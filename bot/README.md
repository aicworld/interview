# interview Plugins

Use LangChain and LLM to build local knowledge model.

## Usage

**init**

```bash
cp config.example.yaml config.yaml
```

**start:**

```bash
cd llm && python fastchat_api_runner.py
cd .. && python main.py
```

## Reference

1. [LangChain](https://github.com/langchain-ai/langchain)